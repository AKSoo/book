DataLad, Run! [1]
-----------------

In previous examples, all changes that happened to the dataset of
the files it contains were
saved to the datasets history by hand. We added larger and smaller
files and saved them, and we also modified smaller file contents and
saved these modification.

Often, however, files or file contents get changed by shell commands
or by scripts containing code.
Consider a data scientist. She has data files with numeric data,
and code scripts in Python, R, Matlab or any other programming language
that will use the data to compute results of figures. Such output is
stored in new files.

But only few weeks after these scripts were executed it can be hard
to remember script for which reason modified or created which
output. How did this result came to be? Which script would she need
to run again on what data to produce this particular figure?

In this section we will experience how DataLad can help
to record the changes in a dataset after execution of a script
from the shell.

Lets say, for example, that you enjoyed the longnow podcasts a lot,
and you start a podcast-night with friends to wind down from all of
the exciting DataLad lectures. They propose to make a
list of speakers and titles to cross out what they've already listened
to, and ask you to prepare such a list.

"Mhh... probably there is a datalad way to do this... wasn't there also
a note about meta data extraction at some point?" But as we're not that
far into the lectures, you decide to write a simple Python script
to generate a tab-separated file that lists speaker and title
name instead.

To do this, we're following a best practice that will reappear in the
later section on YODA principles (todo: link): Collecting all code or
scripts in one dedicated directory per dataset. Therefore,
create a subdirectory ``code/`` in the ``DataLad-101``
superdataset:

.. runrecord:: _examples/DL-101-108-101
   :language: console
   :workdir: dl-101/DataLad-101

   $ mkdir code

Inside of ``Datalad-101/code``, create a simple Python script ``list_titles.py``.
This script will carry out a simple task:
It will loop through the filenames and
write out speaker names and talk titles in a very simple fashion.
The content of this script is written below - copy it into the script.

.. runrecord:: _examples/DL-101-108-102
   :language: console
   :workdir: dl-101/DataLad-101

   $ cat << EOT > code/list_titles.py
   # import modules for path operations and pathname pattern expansion
   from os.path import join, basename
   from glob import glob

   # define a path to the podcasts. Note that this is a relative path,
   # pointing from the root of DataLad-101 to the podcasts:

   path = join('recordings', 'longnow',
               'Long_Now__Seminars_About_Long_term_Thinking', '*')
   # create a list of all file names found under the path
   files = glob(path)
   # define an outfile name:
   outfile = join('recordings', 'Podcasts.tsv')

   # loop through all file names and write speaker and title into the file
   with open(outfile, 'w') as f:
       for file in files:
           # extract speaker name
           author = basename(file).split('__')[1] \
               if len(basename(file).split('__')[1].split('_')) > 1 \
               else '__'.join(basename(file).split('__')[1:3])
           # extract title
           title = '_'.join(basename(file).split(author)[-1].split('__')[1:])
           # write speaker and talk title into the file
           f.write(author + '\t' + title + '\n')
   EOT

Save this script to the dataset.

.. runrecord:: _examples/DL-101-108-103
   :language: console
   :workdir: dl-101/DataLad-101

   $ datalad status

.. runrecord:: _examples/DL-101-108-104
   :language: console
   :workdir: dl-101/DataLad-101

   $ datalad save -m "Add simple script to write a list of podcast speakers and titles" code/list_titles.py

Once we run this script, it will create a new file, ``recordings/Podcasts.tsv``.
Obviously, we could create this file, and subsequently save it to the dataset.
However, just as in the example above,
in a bit of time, we will forget how this file came into existence, or
that the script ``code/list_titles.py`` is associated with this file.

The ``datalad run`` command can help with this. It records a commands impact on a
dataset. Lets try the most simple way to use this command: The ``datalad run``
command, followed by a commit message (``-m "a concise summary"``), and the
command that executes the script from the shell: ``python code/list_titles.py``.
Make sure to run this command from the root of ``DataLad-101``.

.. runrecord:: _examples/DL-101-108-105
   :language: console
   :workdir: dl-101/DataLad-101

   $ datalad run -m "create a list of SALT podcast titles" python code/list_titles.py

Lets take a look into the history:

.. runrecord:: _examples/DL-101-108-106
   :language: console
   :workdir: dl-101/DataLad-101
   :lines: 1-30
   :emphasize-lines: 6, 11, 25

   $ git log -p

The commit message we have supplied with ``-m`` directly after ``datalad run`` appears
in our history as a short summary.

Also, note that the output of the command, the creation of ``recordings/Podcasts.tsv``,
was saved right away.

But what is more in this log entry is the section in between the
``=== Do not change lines below ===`` and
``^^^ Do not change lines above ^^^``.
This is the so-called ``run-record`` - a recording of all of the
information in the ``datalad run`` command, generated by DataLad.
In this case, it is a very simple summary. One informative
part is highlighted:
``"cmd": "python code/list_titles.py"`` is the command that was run.
This information therefore maps the command, and with it the script,
to the output file, in one commit.

Arguably, the run-record is not the most human-readable way to display information.
This representation however is less for the human user (the human user should
rely on their informative commit message), but for DataLad and the ``datalad rerun``
command, which you will see in action at the end of this section.

Note that any ``datalad run`` command that does not result in any changes
in a dataset (no modification of existing content; no additional files)
will not produce any record in the datasets history.

So far, you created a simple ``.tsv`` file of all
speakers and talk titles in the longnow podcasts subdataset.
Let's actually take a look into this file now:

.. runrecord:: _examples/DL-101-108-107
   :language: console
   :workdir: dl-101/DataLad-101
   :lines: 1-30

   $ less recordings/Podcasts.tsv

Not too bad, and certainly good enough for the podcast night people.
What's been cool about creating this file is that it was created with
a script within a ``datalad run`` command. Thanks to ``datalad run``,
the output file ``Podcasts.tsv`` is associated with the script it
generated.

Note that we executed the command from the root of the superdataset.
It is recommended to use ``datalad run`` in the root of the dataset
you want to record the changes in.

Upon reviewing the list you realized that you made a mistake: you only
listed the talks in the SALT series (the
``Long_Now__Seminars_About_Long_term_Thinking`` directory), but not
in the ``Long_Now__Conversations_at_The_Interval/`` directory.
Lets fix this in the script. Replace the contents in ``code/list_titles.py``
with the following:

.. code-block:: python

   # import modules for path operations and pathname pattern expansion
   from os.path import join, basename
   from glob import glob

   # define a path to the podcasts. Note that this is a relative path,
   # pointing from the location the script resides to the podcasts:

   path = join('recordings', 'longnow',
               '*', '*')        # <-- here is the change!
   # create a list of all file names found under the path
   files = glob(path)
   # define an outfile name:
   outfile = join('recordings', 'Podcasts.tsv)

   # loop through all file names and write speaker and title into the file
   with open(outfile, 'w') as f:
       for file in files:
           # extract speaker name
           author = basename(file).split('__')[1] \
               if len(basename(file).split('__')[1].split('_')) > 1 \
               else '__'.join(basename(file).split('__')[1:3])
           # extract title
           title = '_'.join(basename(file).split(author)[-1].split('__')[1:])
           # write speaker and talk title into the file
           f.write(author + '\t' + title + '\n')

.. runrecord:: _examples/DL-101-108-108
   :language: console
   :workdir: dl-101/DataLad-101

   $ cat << EOT > code/list_titles.py
   # import modules for path operations and pathname pattern expansion
   from os.path import join, basename
   from glob import glob

   # define a path to the podcasts. Note that this is a relative path,
   # pointing from the root of DataLad-101 to the podcasts:

   path = join('recordings', 'longnow',
               '*', '*')        # <-- here is the change!
   # create a list of all file names found under the path
   files = glob(path)
   # define an outfile name:
   outfile = join('recordings', 'Podcasts.tsv')

   # loop through all file names and write speaker and title into the file
   with open(outfile, 'w') as f:
       for file in files:
           # extract speaker name
           author = basename(file).split('__')[1] \
               if len(basename(file).split('__')[1].split('_')) > 1 \
               else '__'.join(basename(file).split('__')[1:3])
           # extract title
           title = '_'.join(basename(file).split(author)[-1].split('__')[1:])
           # write speaker and talk title into the file
           f.write(author + '\t' + title + '\n')
   EOT

Because the script is now modified, save the modifications to the dataset.
We can use the shorthand "BF" to denote "Bug fix" in the commit message.

.. runrecord:: _examples/DL-101-108-109
   :language: console
   :workdir: dl-101/DataLad-101

   $ datalad status

.. runrecord:: _examples/DL-101-108-110
   :language: console
   :workdir: dl-101/DataLad-101

   $ datalad save -m "BF: list both directories content" code/list_titles.py

What we *could* do is to run the same ``datalad run`` command as before to recreate
the file, but now with all of the contents:

.. code-block:: bash

   # don't execute this!
   $ datalad run -m "create a list of SALT podcast titles" python code/list_titles.py

However, think about any situation where the command would be longer than this,
or that is many months past the first execution. It wouldn't be easy to remember
the command, nor would it be very convenient to copy it from the runrecord.

As promised, there is a datalad way of re-executing a ``run`` command, and we'll
try it in this very simple situation. To re-execute a ``datalad run`` command,
find the checksum of its commit and use it as an argument for the
``datalad rerun`` command.

.. runrecord:: _examples/DL-101-108-111
   :language: console
   :workdir: dl-101/DataLad-101
   :lines: 1-12
   :emphasize-lines: 8

   $ git log -2

Take that checksum and paste it after ``datalad rerun``.

.. runrecord:: _examples/DL-101-108-112
   :language: console
   :workdir: dl-101/DataLad-101
   :realcommand: echo "$ datalad rerun $(git rev-parse HEAD~1)" && datalad rerun $(git rev-parse HEAD~1)

Now DataLad has made use out of the runrecord, and re-executed the command. Because we
updated the script, the output now contains the podcast titles of both subdirectories.
An easy way to check whether a ``datalad rerun`` has changed the desired output file is
to check whether the rerun command appears in the datasets history: If a ``datalad rerun``
does not add or change any content in the dataset, it will not be recorded in the history.

We can see that ``datalad run`` was recorded. In the datasets history, this action is
committed by Datalad under the original commit message:

.. runrecord:: _examples/DL-101-108-113
   :language: console
   :workdir: dl-101/DataLad-101

   git log -1

Note that ``datalad rerun`` works with ``datalad run`` or ``datalad rerun`` commands,
but not with any other type of datalad command in your history. Therefore, make it a
habit to record the execution of scripts by plugging it into ``datalad run``.

This very basic example of a ``datalad run`` is as simple as it can get, but is already
convenient from a memory-load perspective: Now you don't need to
remember the commands or scripts involved in creating an output.

However, the next section will demonstrate how ``datalad run`` becomes handy in
more complex standard use cases: situations with *locked* contents.

But prior to that, make a note about ``datalad run`` and ``datalad rerun`` in your
``notes.txt`` file.

.. runrecord:: _examples/DL-101-108-114
   :language: console
   :workdir: dl-101/DataLad-101

   $ cat << EOT >> notes.txt
   The datalad run command can record the impact a script or command has on a Dataset.
   In its most simple form, datalad run only takes a commit message and the command that
   should be executed.

   Any datalad run command can be re-executed by using its commit checksum as an argument
   in datalad rerun CHECKSUM. DataLad will take information form the runrecord of the original
   commit, and re-execute it. If no changes happen with a rerun, the command will not be written
   to history. Note: you can also rerun a datalad rerun command!
   EOT

Finally, save this note.

.. runrecord:: _examples/DL-101-108-115
   :language: console
   :workdir: dl-101/DataLad-101

   datalad save -m "add note on basic datalad run and datalad rerun" notes.txt